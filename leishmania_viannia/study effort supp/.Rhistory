train <- feature_data[train_index,]; train_matrix <- as.matrix(train); d_train_matrix <- xgb.DMatrix(train_matrix[,-1], label= train_matrix[,1])
test <- feature_data[-train_index,]; test_matrix <- as.matrix(test); d_test_matrix <- xgb.DMatrix(test_matrix[,-1], label= test_matrix[,1])
#get AUC with all the features
xgb.base <- xgboost(data = d_train_matrix,
eta = mean_params[mean_params$Group.1=='eta','value'],
max_depth = round(mean_params[mean_params$Group.1=='max_depth','value']),
min_child_weight = mean_params[mean_params$Group.1=='min_child','value'],
subsample = mean_params[mean_params$Group.1=='subsample','value'],
colsample_bytree = mean_params[mean_params$Group.1=='colsample_bytree','value'],
gamma = mean_params[mean_params$Group.1=='gamma','value'],
nrounds = 15,
# scale_pos_weight = 4,
objective = "reg:squarederror",
eval_metric = "mae")
# To return the SHAP values and ranked features by mean|SHAP|
shap_values <- shap.values(xgb_model = xgb.base, X_train = test_matrix[,-1])
# The ranked features by mean |SHAP| for feature importance
means <- as.data.frame(shap_values$mean_shap_score) #this gets global feature importance - this is the mean SHAP value per feature
means$Feature <- rownames(means) #this just makes sure that the SHAP values is associated with each feature
means$iter <- i #saving iteration to potentially aggregate and plot better
means_df <- rbind(means_df, means)
#shap scores per observation for partial dependence (shap value X feature value)
dependence_plots <- as.data.frame(cbind(analysis_data_v2[-train_index, ], shap_values$shap_score)) #this gets a dataframe of SHAP values per obs per feature (y axis), and binds it to the original dataframe so you retain the associated feature value (x axis)
dependence_plots$iter <- i
dependence_df <- rbind(dependence_df, dependence_plots)
}
names(means_df) <- c("mean_shap_score", "Feature", "iter")
write.csv(means_df, "shapley variable importance study effort leishmania sept 20 2022.csv")
write.csv(dependence_df, "shapley dependence study leishmania sept 20 2022.csv")
#make a list of features to iterate through
features <- names(feature_data)[2:ncol(feature_data)]
feature_names <- features
pc <- c("mean_crop_cover", "mean_urban_cover","mean_tree_cover")
hab <- c("forest","savanna","shrubland","grassland","wetlands","rocky_areas","desert","artificial")
diet <- c("MammalEater","Insectivore","Frugivore","Granivore","Folivore")
activity <- c("ActivityCycle.1", "ActivityCycle.2", "ActivityCycle.3")
strata <- c("ForStrat.ValueA", "ForStrat.ValueAr", "ForStrat.ValueG", "ForStrat.ValueS")
#order <- c("MSW05_OrderPrimates","MSW05_OrderRodentia","MSW05_OrderCarnivora","MSW05_OrderChiroptera","MSW05_OrderDidelphimorphia","MSW05_OrderSoricomorpha","MSW05_OrderLagomorpha","MSW05_OrderCingulata","MSW05_OrderPilosa","MSW05_OrderArtiodactyla",
# #           "MSW05_OrderMicrobiotheria", "MSW05_OrderPaucituberculata", "MSW05_OrderPerissodactyla")
phylo <- c("V1","V2","V3","V4","V5","V6")
trophic <- c("TrophicLevel.yOmnivore","TrophicLevel.yCarnivore","TrophicLevel.yHerbivore")
drop_traits <- c(pc, hab, diet, activity, strata, phylo, trophic)
features <- features[!features %in% drop_traits]
list_features <- as.list(features)
list_features
list_features[[25]] <- pc
list_features[[26]] <- hab
list_features[[27]] <- diet
list_features[[28]] <- activity
list_features[[29]] <- strata
list_features[[30]] <- phylo
list_features[[31]] <- trophic
# #list_features[[33]] <- order
feature_names <- c(features, "pc", "hab", "diet", "activity", "strata", "phylo", "trophic") #took out order
sum_mean_shap_scores <- c()
for(j in 1:100) {
sub_data <- subset(means_df, iter == j)
new_df <- c()
for(i in 1:length(list_features)) { #31 features
new_dat <- sub_data[sub_data$Feature %in% list_features[[i]], ]
shap_sum <-  sum(new_dat$mean_shap_score)
new_df0 <- data.frame(Feature = feature_names[i], mean_shap_score = shap_sum, iter = j)
new_df <- rbind(new_df, new_df0)
}
sum_mean_shap_scores <- rbind(sum_mean_shap_scores, new_df)
}
# #get top variables for further analysis
aggregate_mean <- aggregate(mean_shap_score ~ Feature, data = sum_mean_shap_scores,
FUN = function(x) c(mean = mean(x),
median = quantile(x, probs = 0.5),
lower.q = quantile(x, probs = 0.05),
upper.q = quantile(x, probs = 0.95)))
aggregate_mean <- do.call(data.frame, aggregate_mean)
write.csv(aggregate_mean, "mean sum shap scores study effort leishmania july 20.csv")
imp_df <- subset(aggregate_mean, mean_shap_score.lower.q.5. > 0)
importance_plot_all <- ggplot(imp_df, aes(x = reorder(Feature, mean_shap_score.lower.q.5.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |shap value|') +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
#scale_color_manual(values=c('grey',colors[c(3,5,8)])) +
coord_flip() + theme_bw(base_size = 14) ##convert y to sd from the mean
importance_plot_all
aggregate_mean
importance_plot_all <- ggplot(aggregate_mean, aes(x = reorder(Feature, mean_shap_score.lower.q.5.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |shap value|') +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
#scale_color_manual(values=c('grey',colors[c(3,5,8)])) +
coord_flip() + theme_bw(base_size = 14) ##convert y to sd from the mean
importance_plot_all
#------------------------------------------------------
# Set up
#------------------------------------------------------
rm(list=ls())
library(xgboost)
library(rBayesianOptimization)
library(caret)
library(rsample) #to split stratified data
library(dplyr)
library(SHAPforxgboost)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
#####
##### title: BRT for identifying hosts likely to be exposed to parasites in the leishmania genus - dont use imputed data
##### author: Caroline Glidden
##### version: 09/10/2021
########calculates feature importance
########calculates pdps
########uses bootstrap values to get host predictions
#------------------------------------------------------
# Set up
#------------------------------------------------------
rm(list=ls())
library(xgboost)
library(rBayesianOptimization)
library(caret)
library(rsample) #to split stratified data
library(dplyr)
library(SHAPforxgboost)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
#------------------------------------------------------
#read in final trait data -- that was cleaned and reduced in the variable selection script
#------------------------------------------------------
analysis_data <- readRDS("../cleaned data/analysis data/pubmed_analysis_data.rds")
#analysis_data <- readRDS("trait_data_small.rds")
mean_params <- read.csv("study mean parameter table july 6 2022.csv")
#mean_params <- read.csv("mean parameter table leishmania july 8 2022.csv")
#------------------------------------------------------#
#Feature importance - shapley                          #
#------------------------------------------------------#
####var importance --- use this to decide pdps to run
means_df <- c()
dependence_df <- c()
for(i in 1:100){
set.seed(i*1226)
#shuffle before creating kfolds
rows <- sample(nrow(analysis_data))
feature_data <- analysis_data[rows,]
##create test & train split
train_index <- createDataPartition(feature_data$pubmed.count, p = .7, list = FALSE)
train <- feature_data[train_index,]; train_matrix <- as.matrix(train); d_train_matrix <- xgb.DMatrix(train_matrix[,-1], label= train_matrix[,1])
test <- feature_data[-train_index,]; test_matrix <- as.matrix(test); d_test_matrix <- xgb.DMatrix(test_matrix[,-1], label= test_matrix[,1])
#get AUC with all the features
xgb.base <- xgboost(data = d_train_matrix,
eta = mean_params[mean_params$Group.1=='eta','value'],
max_depth = round(mean_params[mean_params$Group.1=='max_depth','value']),
min_child_weight = mean_params[mean_params$Group.1=='min_child','value'],
subsample = mean_params[mean_params$Group.1=='subsample','value'],
colsample_bytree = mean_params[mean_params$Group.1=='colsample_bytree','value'],
gamma = mean_params[mean_params$Group.1=='gamma','value'],
nrounds = 15,
# scale_pos_weight = 4,
objective = "reg:squarederror",
eval_metric = "mae")
# To return the SHAP values and ranked features by mean|SHAP|
shap_values <- shap.values(xgb_model = xgb.base, X_train = test_matrix[,-1])
# The ranked features by mean |SHAP| for feature importance
means <- as.data.frame(shap_values$mean_shap_score) #this gets global feature importance - this is the mean SHAP value per feature
means$Feature <- rownames(means) #this just makes sure that the SHAP values is associated with each feature
means$iter <- i #saving iteration to potentially aggregate and plot better
means_df <- rbind(means_df, means)
#shap scores per observation for partial dependence (shap value X feature value)
dependence_plots <- as.data.frame(cbind(analysis_data_v2[-train_index, ], shap_values$shap_score)) #this gets a dataframe of SHAP values per obs per feature (y axis), and binds it to the original dataframe so you retain the associated feature value (x axis)
dependence_plots$iter <- i
dependence_df <- rbind(dependence_df, dependence_plots)
}
names(means_df) <- c("mean_shap_score", "Feature", "iter")
write.csv(means_df, "shapley variable importance study effort vianna sept 20 2022.csv")
write.csv(dependence_df, "shapley dependence study vianna sept 20 2022.csv")
#######
#aggregate per group of features for each iteration
#######
#make a list of features to iterate through
features <- names(feature_data)[2:ncol(feature_data)]
feature_names <- features
pc <- c("mean_crop_cover", "mean_urban_cover","mean_tree_cover")
hab <- c("forest","savanna","shrubland","grassland","wetlands","rocky_areas","desert","artificial")
diet <- c("MammalEater","Insectivore","Frugivore","Granivore","Folivore")
activity <- c("ActivityCycle.1", "ActivityCycle.2", "ActivityCycle.3")
strata <- c("ForStrat.ValueA", "ForStrat.ValueAr", "ForStrat.ValueG", "ForStrat.ValueS")
#order <- c("MSW05_OrderPrimates","MSW05_OrderRodentia","MSW05_OrderCarnivora","MSW05_OrderChiroptera","MSW05_OrderDidelphimorphia","MSW05_OrderSoricomorpha","MSW05_OrderLagomorpha","MSW05_OrderCingulata","MSW05_OrderPilosa","MSW05_OrderArtiodactyla",
# #           "MSW05_OrderMicrobiotheria", "MSW05_OrderPaucituberculata", "MSW05_OrderPerissodactyla")
phylo <- c("V1","V2","V3","V4","V5","V6")
trophic <- c("TrophicLevel.yOmnivore","TrophicLevel.yCarnivore","TrophicLevel.yHerbivore")
drop_traits <- c(pc, hab, diet, activity, strata, phylo, trophic)
features <- features[!features %in% drop_traits]
list_features <- as.list(features)
list_features[[25]] <- pc
list_features[[26]] <- hab
list_features[[27]] <- diet
list_features[[28]] <- activity
list_features[[29]] <- strata
list_features[[30]] <- phylo
list_features[[31]] <- trophic
# #list_features[[33]] <- order
feature_names <- c(features, "pc", "hab", "diet", "activity", "strata", "phylo", "trophic") #took out order
sum_mean_shap_scores <- c()
for(j in 1:100) {
sub_data <- subset(means_df, iter == j)
new_df <- c()
for(i in 1:length(list_features)) { #31 features
new_dat <- sub_data[sub_data$Feature %in% list_features[[i]], ]
shap_sum <-  sum(new_dat$mean_shap_score)
new_df0 <- data.frame(Feature = feature_names[i], mean_shap_score = shap_sum, iter = j)
new_df <- rbind(new_df, new_df0)
}
sum_mean_shap_scores <- rbind(sum_mean_shap_scores, new_df)
}
# #get top variables for further analysis
aggregate_mean <- aggregate(mean_shap_score ~ Feature, data = sum_mean_shap_scores,
FUN = function(x) c(mean = mean(x),
median = quantile(x, probs = 0.5),
lower.q = quantile(x, probs = 0.05),
upper.q = quantile(x, probs = 0.95)))
aggregate_mean <- do.call(data.frame, aggregate_mean)
write.csv(aggregate_mean, "mean sum shap scores study effort vianna july 20.csv")
imp_df <- subset(aggregate_mean, mean_shap_score.lower.q.5. > 0)
importance_plot_all <- ggplot(aggregate_mean, aes(x = reorder(Feature, mean_shap_score.lower.q.5.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |shap value|') +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
#scale_color_manual(values=c('grey',colors[c(3,5,8)])) +
coord_flip() + theme_bw(base_size = 14) ##convert y to sd from the mean
rm(list=ls())
library(xgboost)
library(rBayesianOptimization)
library(caret)
library(rsample) #to split stratified data
library(dplyr)
library(SHAPforxgboost)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
#------------------------------------------------------
#read in final trait data -- that was cleaned and reduced in the variable selection script
#------------------------------------------------------
analysis_data <- readRDS("../cleaned data/analysis data/pubmed_analysis_data.rds")
#analysis_data <- readRDS("trait_data_small.rds")
mean_params <- read.csv("study mean parameter table july 6 2022.csv")
#mean_params <- read.csv("mean parameter table leishmania july 8 2022.csv")
names(analysis_data)
means_df <- c()
dependence_df <- c()
for(i in 1:100){
set.seed(i*1226)
#shuffle before creating kfolds
rows <- sample(nrow(analysis_data))
analysis_data_v2 <- analysis_data[rows,]
feature_data <- analysis_data_v2[,-2]
##create test & train split
train_index <- createDataPartition(feature_data$pubmed.count, p = .7, list = FALSE)
train <- feature_data[train_index,]; train_matrix <- as.matrix(train); d_train_matrix <- xgb.DMatrix(train_matrix[,-1], label= train_matrix[,1])
test <- feature_data[-train_index,]; test_matrix <- as.matrix(test); d_test_matrix <- xgb.DMatrix(test_matrix[,-1], label= test_matrix[,1])
#get AUC with all the features
xgb.base <- xgboost(data = d_train_matrix,
eta = mean_params[mean_params$Group.1=='eta','value'],
max_depth = round(mean_params[mean_params$Group.1=='max_depth','value']),
min_child_weight = mean_params[mean_params$Group.1=='min_child','value'],
subsample = mean_params[mean_params$Group.1=='subsample','value'],
colsample_bytree = mean_params[mean_params$Group.1=='colsample_bytree','value'],
gamma = mean_params[mean_params$Group.1=='gamma','value'],
nrounds = 15,
# scale_pos_weight = 4,
objective = "reg:squarederror",
eval_metric = "mae")
# To return the SHAP values and ranked features by mean|SHAP|
shap_values <- shap.values(xgb_model = xgb.base, X_train = test_matrix[,-1])
# The ranked features by mean |SHAP| for feature importance
means <- as.data.frame(shap_values$mean_shap_score) #this gets global feature importance - this is the mean SHAP value per feature
means$Feature <- rownames(means) #this just makes sure that the SHAP values is associated with each feature
means$iter <- i #saving iteration to potentially aggregate and plot better
means_df <- rbind(means_df, means)
#shap scores per observation for partial dependence (shap value X feature value)
dependence_plots <- as.data.frame(cbind(analysis_data_v2[-train_index, ], shap_values$shap_score)) #this gets a dataframe of SHAP values per obs per feature (y axis), and binds it to the original dataframe so you retain the associated feature value (x axis)
dependence_plots$iter <- i
dependence_df <- rbind(dependence_df, dependence_plots)
}
names(means_df) <- c("mean_shap_score", "Feature", "iter")
write.csv(means_df, "shapley variable importance study effort vianna sept 20 2022.csv")
write.csv(dependence_df, "shapley dependence study vianna sept 20 2022.csv")
#make a list of features to iterate through
features <- names(feature_data)[2:ncol(feature_data)]
feature_names <- features
pc <- c("mean_crop_cover", "mean_urban_cover","mean_tree_cover")
hab <- c("forest","savanna","shrubland","grassland","wetlands","rocky_areas","desert","artificial")
diet <- c("MammalEater","Insectivore","Frugivore","Granivore","Folivore")
activity <- c("ActivityCycle.1", "ActivityCycle.2", "ActivityCycle.3")
strata <- c("ForStrat.ValueA", "ForStrat.ValueAr", "ForStrat.ValueG", "ForStrat.ValueS")
#order <- c("MSW05_OrderPrimates","MSW05_OrderRodentia","MSW05_OrderCarnivora","MSW05_OrderChiroptera","MSW05_OrderDidelphimorphia","MSW05_OrderSoricomorpha","MSW05_OrderLagomorpha","MSW05_OrderCingulata","MSW05_OrderPilosa","MSW05_OrderArtiodactyla",
# #           "MSW05_OrderMicrobiotheria", "MSW05_OrderPaucituberculata", "MSW05_OrderPerissodactyla")
phylo <- c("V1","V2","V3","V4","V5","V6")
trophic <- c("TrophicLevel.yOmnivore","TrophicLevel.yCarnivore","TrophicLevel.yHerbivore")
drop_traits <- c(pc, hab, diet, activity, strata, phylo, trophic)
features <- features[!features %in% drop_traits]
list_features <- as.list(features)
list_features[[25]] <- pc
list_features[[26]] <- hab
list_features[[27]] <- diet
list_features[[28]] <- activity
list_features[[29]] <- strata
list_features[[30]] <- phylo
list_features[[31]] <- trophic
# #list_features[[33]] <- order
feature_names <- c(features, "pc", "hab", "diet", "activity", "strata", "phylo", "trophic") #took out order
sum_mean_shap_scores <- c()
for(j in 1:100) {
sub_data <- subset(means_df, iter == j)
new_df <- c()
for(i in 1:length(list_features)) { #31 features
new_dat <- sub_data[sub_data$Feature %in% list_features[[i]], ]
shap_sum <-  sum(new_dat$mean_shap_score)
new_df0 <- data.frame(Feature = feature_names[i], mean_shap_score = shap_sum, iter = j)
new_df <- rbind(new_df, new_df0)
}
sum_mean_shap_scores <- rbind(sum_mean_shap_scores, new_df)
}
# #get top variables for further analysis
aggregate_mean <- aggregate(mean_shap_score ~ Feature, data = sum_mean_shap_scores,
FUN = function(x) c(mean = mean(x),
median = quantile(x, probs = 0.5),
lower.q = quantile(x, probs = 0.05),
upper.q = quantile(x, probs = 0.95)))
aggregate_mean <- do.call(data.frame, aggregate_mean)
write.csv(aggregate_mean, "mean sum shap scores study effort vianna july 20.csv")
imp_df <- subset(aggregate_mean, mean_shap_score.lower.q.5. > 0)
importance_plot_all <- ggplot(aggregate_mean, aes(x = reorder(Feature, mean_shap_score.lower.q.5.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |shap value|') +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
#scale_color_manual(values=c('grey',colors[c(3,5,8)])) +
coord_flip() + theme_bw(base_size = 14) ##convert y to sd from the mean
importance_plot_all
mean_importance_leish <- read.csv("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_leishmania/study effort supp/mean sum shap scores study effort leishmania july 20.csv")
imp_df_leish <- mean_importance_leish
names(mean_importance_leish)
ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.mean), y = mean_shap_score.mean, color=trait_type)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~bold(b.)~" "~italic(L. (Leishmania))~" ")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
scale_color_manual(values=colors, 'trait type') +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.mean), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~bold(b.)~" "~italic(L. (Leishmania))~" ")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.mean), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.upper.q.95.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_leishmania/study effort supp/leish_studyEff_importance.png", importance_plot_leish, dpi=600)
importance_plot_leish <- ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.upper.q.95.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_leishmania/study effort supp/leish_studyEff_importance.png", importance_plot_leish, dpi=600)
importance_plot_leish
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_leishmania/study effort supp/shapley dependence study leishmania sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
names(pd_df_iter_leish)
114-59
58-2
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(3:58,115, 116)] %>%
tidyr::pivot_longer(cols = 1:55, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(59:114, 119)] %>%
tidyr::pivot_longer(cols = 1:55, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(3:58,115, 116)] %>%
tidyr::pivot_longer(cols = 1:55, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(59:114, 115, 116)] %>%
tidyr::pivot_longer(cols = 1:55, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "WeaningAge_d", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4, labeller = trait_labeller) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
pdp_leish_se <- ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Leishmania))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_leishmania/study effort supp/leish_studyEff_pdps.png", pdp_leish_se, dpi=600)
hist(analysis_data$pubmed.count)
######Figures for leish host paper - leish study effort
library(ggplot2)
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(foreach)
library(speciesgeocodeR)
###########
##figure 2: variable importance
###########
colors0 <- nationalparkcolors::park_palette("Badlands", 3)
colors <- c(colors0[c(1,3,2)], "grey")
mean_importance_leish <- read.csv("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/mean sum shap scores study effort leishmania july 20.csv")
#imp_df_leish <- subset(mean_importance_leish, mean_shap_score.lower.q.5. > 0)
imp_df_leish <- mean_importance_leish
mean_importance_leish <- read.csv("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/mean sum shap scores study effort vianna july 20.csv")
imp_df_leish <- mean_importance_leish
importance_plot_vianna <- ggplot(imp_df_leish, aes(x = reorder(Feature, mean_shap_score.upper.q.95.), y = mean_shap_score.mean)) +
geom_point(size = 3) + xlab('feature') + ylab('mean |SHAP value|') +
ggtitle(expression(~italic(L. (Vianna))~" study effort")) +
geom_errorbar(aes(ymin = mean_shap_score.lower.q.5., ymax = mean_shap_score.upper.q.95.), position = "dodge", width = 0.4, size = 1.5) +
coord_flip() +
theme_bw(base_size = 12) +
theme(legend.position = "none",
legend.key=element_blank())
importance_plot_vianna
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/vianna_studyEff_importance.png", importance_plot_vianna, dpi=600)
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
names(pd_df_iter_leish)
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(3:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:54, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:54, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
111-58
feature_value <- pd_df_iter_leish[,c(4:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
pdp_vianna_se <- ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Vianna))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
pdp_vianna_se
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/vianna_studyEff_pdps.png", pdp_leish_se, dpi=600)
